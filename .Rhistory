viewinfor()
viewinfo()
class(flags)
cls_list<- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
?sapply
cls_vect <- sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[,11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[,19:23]
lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3,4,5,5,5,6,6))
unique_vals <- lapply(flags, unique)
unique_vals
lapply(unique_vals,length)
sapply(unique_vals,length)
sapply(flags,unique)
lapply(unique_vals, function(elem) elem[2])
vapply(flags, unique, numeric(1))
ok()
sapply(flags,class)
vapply(flags,class,character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
clear()
clr()
library(datasets)
data("iris")
?iris
head(iris)
tapply(iris$Sepal.Length, iris$Species, mean)
sapply(iris[,1:4], mean)
apply(iris[,1:4], mean)
colMeans(iris)
apply(iris[,1:4],2, mean)
?apply
apply(iris[,1:4],1, mean)
apply(iris[,1:4],2, mean)
data(mtcars)
?mtcars
head(mtcars)
dim(mtcars)
dimname(mtcars)
dimnames(mtcars)
head(mtcars)
with(mtcars, tapply(mpg, cyl, mean))
?with
lapply(mtcars,mean)
split(mtcars, mtcars$cyl)
mean(mtcars$mpg, mtcars$cyl)
?mean
sapply(split(mtcars$mpg, mtcars$cyl), mean)
sapply(mtcars, cyl, mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
apply(mtcars, 2, mean)
head(mtcars)
with(mtcars, tapply(hp, cyl, mean))
hp_vect <- with(mtcars, tapply(hp, cyl, mean))
class(hp_vect)
hp_vect <- as.numeric(hp_vect)
class(hp_vect)
hp_vect
with(hp_vect, 8 - 4)
hp_vect[3] - hp_vect[1]
debug(ls)
ls
ls()
?debug
ls()
undebug(ls)
undebug(ls)
ls
ls()
library(swirl)
swirl()
?sample
sample(1:6, 4, replace=TRUE)
sample(1:6, 4, replace=TRUE)
sample(1:10,10)
sample(1:20,10)
LETTERS
letters
sample(LETTERS)
flips <- sample(c(0,1), 100, replace=TRUE, prob = c(0.3, 0.7))
flips
sum(flips)
?rbinom
rbinom(1,size=100, prob=0.7)
rbinom(100,size=100, prob=0.7)
flips2<- rbinom(100, size=1,prob=0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10,mean=100, sd=25)
?rpois
rpois(5,10)
?replicate
?replicate
my_pois<-replicate(100,rpois(5,10))
my_pois
cm<- colMeans(my_pois)
hist(cm)
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(x=cars$speed, y =cars$dist)
plot(x=cars$dist, y=cars$speed)
plot(cars$speed,cars$dist)
plot(x=cars$speed,y=cars$dist, xlab = "Speed")
plot(x=cars$speed,y=cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x = cars$speed,y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
?plot
plot(cars, main = "My Plot" )
plot(cars, sub = "My Plot Subtitle" )
?par
plot(cars, col = 2)
plot(cars, xlim = c(10, 15))
?points
plot(cars, pch =2
)
data(mtcars)
?boxplot
play()
head(mtcars)
tail(mtcars)
tail(mtcars, 20)
nxt()
boxplot(mtcars$mpg~mtcars$cyl, mtcars)
boxplot(formula = mtcars$mpg~mtcars$cyl, data = mtcars)
boxplot(formula = mpg~cyl, data = mtcars)
hist(mtcars$mpg)
q()
getwd()
tables()
library(data.table)
install.packages(data.table)
install.packages("data.table")
installed.packages()
library(data.table)
tables()
DT = data.table(x=rnorm(9), y = rep(c("a","b", "c"), each=3), z=rnorm(9))
head(DT,3)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "mycsv.csv", method = "curl")
csvData <- read.csv("mycsv.csv")
head(csvData)
q()
library(swirl)
install_from_swirl("Exploratory Data Analysis")
swirl()
ls()
rm(list=ls())
x=2
t=3
rm(t)
rm(x)
install_from_swirl("Data Analysis")
swirl()
install_from_swirl("Getting and Cleaning Data")
install_from_swirl("Getting and Cleaning Data")
swirl()
swirl::install_course("Getting and Cleaning Data")
swirl()
swirl()
viewinfo()
info()
bye()
q()
library(swirl)
ls()
rm(ls())
rm(list=ls())
swirl()
View(top_counts)
top_counts <- filter(pack_sum, count > quantile(count, probs = 0.99))
View(top_counts)
arrange(top_counts, desc(count))
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
install_packages("ggplot2")
install_packag
install.packages("ggplot2")
qualtile(pack_sum$unique, probs = 0.99)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(top_counts, unique > 465)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
submit()
submit()
library(tidyr)
bye()
rm(list=ls())
swirl()
students
?gather
bye()
q()
install.packages("lubridate")
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package=lubridate)
this_day = today()
this_day <- today()
this_day
rm(list=ls())
this_day = today()
year(this_day)
wday(this_day)
wday(this_day, lable = TRUE)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
second(this_moment)
ymd("1989-05-17")
my_date <-ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy(March 12, 1975)
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920/1/2")
bye()
q()
library(swirl)
swirl()
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours=8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 7, minutes= 45)
this_moment
?now
nyc <- now(tzone = "America/New_York")
nyc
depart <- nyc +days(2)
depart
depart <- update(depart, hours=17, minutes=34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, tzone= "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?interval
how_long <- interval(last_time, arrive)
as.period(how_long)
stopwatch()
q()
setwd("data_cleaning")
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",
temp, method = "curl")
data <- read.table(unz(temp, "X_test.txt"))
unlink(temp)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",
"HAR.zip", method = "curl")
xtest <- read.table(unz("HAR.zip", "/test/X_test.txt"))
?unzip
unzip ("dataset.zip", exdir = "./")
unzip ("HAR.zip", exdir = "./")
xtest = read.table("./UCI HAR Dataset/test/X_test.txt")
rm(list=ls())
xtest = read.table("./UCI HAR Dataset/test/X_test.txt")
xtest
head(xtest)
View(xtest)
str(xtest)
ytest = read.table("./UCI HAR Dataset/test/y_test.txt")
View(ytest)
xtrain = read.table("./UCI HAR Dataset/train/X_train.txt")
ytrain = read.table("./UCI HAR Dataset/train/y_train.txt")
ytrain
head(ytrain, 20)
head(xtrain, 20)
head(ytest, 20)
xmerged = rbind(xtrain, xtest)
ymerged = rbind(ytrain, ytest)
features = read.table("./UCI HAR Dataset/features.txt")
features = features(,2)
features = features[,2]
fstr(features)
str(features)
features = read.table("./UCI HAR Dataset/features.txt")[,2]
rm(features)
features = read.table("./UCI HAR Dataset/features.txt")[,2]
features = as.character(features)
features = read.table("./UCI HAR Dataset/features.txt")[,2]
features = as.character(read.table("./UCI HAR Dataset/features.txt")[,2])
features
grep("mean|std", features)
View(features)
names(xmerged) = features
?sub
features = sub("//(//)", "", features)
features
features = sub("()", "", features)
features
features = sub("//()", "", features)
features
gsub("\\(|\\)", "", features)
features = gsub("\\(|\\)", "", features)
features
features = as.character(read.table("./UCI HAR Dataset/features.txt")[,2])
features
names(xmerged) = features
?grepl
grepl("mean|std", features)
selected <- xmerged[,grepl("mean|std", features)]
sum(grepl("mean|std", features))
merged = cbind(ymerged, xmerged)
head(merged)
xmerged = rbind(xtrain, xtest)
features = as.character(read.table("./UCI HAR Dataset/features.txt")[,2])
names(xmerged) = features
xmerged <- xmerged[,grepl("mean|std", names(xmerged))]
ymerged = rbind(ytrain, ytest)
names(ymerged) = "activity"
names(ymerged)
subjectmerged = rbind(subjecttrain, subjecttest)
names(subjectmerged) = "subject"
subjecttrain = read.table("./UCI HAR Dataset/train/subject_train.txt")
subjecttest = read.table("./UCI HAR Dataset/test/subject_test.txt")
subjectmerged = rbind(subjecttrain, subjecttest)
names(subjectmerged) = "subject"
merged = cbind(subjectmerged,ymerged, xmerged)
View(merged)
activityLabels = read.table("./UCI HAR Dataset/activity_labels.txt")
names(ymerged) = "activityIndex"
names(activityLabels) = c("activityIndex", "activityName")
ymerged = merge(ymerged, activityLabels, by = "activityIndex")
View(ymerged)
merged = cbind(subjectmerged,ymerged, xmerged)
str(merged)
library(dplyr)
tidyDataset = tbl_df(merged)
tidyDataset
?group_by
tidyDataset=group_by(tidyDataset, subject, activityName)
tidyDataset
?summarize
newDataset = summarize(tidyDataset, mean)
newDataset = summarize(tidyDataset, mean(tidyDataset[,4:82]))
newDataset
View(tidyDataset)
newDataset = summarize(tidyDataset, mean())
?summarize_each
newDataset = summarize_each(tidyDataset, funs(mean))
newDataset
view(newDataset)
View(newDataset)
newDataset = summarize_each(tidyDataset, funs(mean))
rm(list=ls())
?rm
?rename
# read and merge train & test datasets
X = rbind(tbl_df(read.table("./UCI HAR Dataset/train/X_train.txt")),
tbl_df(read.table("./UCI HAR Dataset/test/X_test.txt")))
y = rbind(tbl_df(read.table("./UCI HAR Dataset/train/y_train.txt")),
tbl_df(read.table("./UCI HAR Dataset/test/y_test.txt")))
subject = rbind(tbl_df(read.table("./UCI HAR Dataset/train/subject_train.txt")),
tbl_df(read.table("./UCI HAR Dataset/test/subject_test.txt")))
rename(x, read.table("./UCI HAR Dataset/features.txt")[,2]))
rename(x, read.table("./UCI HAR Dataset/features.txt")[,2])
rename(X, read.table("./UCI HAR Dataset/features.txt")[,2])
rename(X, read.table("./UCI HAR Dataset/features.txt")[,2] = names(X))
names(X) = (read.table("./UCI HAR Dataset/features.txt")[,2])
xx = select(X, contains("mean|std"))
View(X)
features = gsub("//(|//)|-", "", read.table("./UCI HAR Dataset/features.txt")[,2])
features = gsub("\\(|\\)|-", "", read.table("./UCI HAR Dataset/features.txt")[,2])
names(X) = gsub("\\(|\\)|-", "", read.table("./UCI HAR Dataset/features.txt")[,2])
xx = select(X, contains("mean|std"))
xx=X[,grepl("mean|std", names(X))]
X <- X[,grepl("mean|std", names(X))]
rm(xx)
activityLabels = tbl_df(read.table("./UCI HAR Dataset/activity_labels.txt")) %>%
rename(activityIndex = V1, activityName = V2)
y = merge(y, activityLabels, by = "activityIndex") %>%
select(-activityIndex)
names(y) = "activityIndex"
names(subject) = "subject"
y = merge(y, activityLabels, by = "activityIndex") %>%
select(-activityIndex)
mergedDataset = cbind(subject, y, X)
newDataset= group_by(mergedDataset, subject, activityName) %>%
summarize_each(funs(mean))
rm(list=ls())
# read and merge train & test datasets
X = rbind(tbl_df(read.table("./UCI HAR Dataset/train/X_train.txt")),
tbl_df(read.table("./UCI HAR Dataset/test/X_test.txt")))
y = rbind(tbl_df(read.table("./UCI HAR Dataset/train/y_train.txt")),
tbl_df(read.table("./UCI HAR Dataset/test/y_test.txt")))
subject = rbind(tbl_df(read.table("./UCI HAR Dataset/train/subject_train.txt")),
tbl_df(read.table("./UCI HAR Dataset/test/subject_test.txt")))
# read features and pass them as variable names of X
names(X) = gsub("\\(|\\)|-", "", read.table("./UCI HAR Dataset/features.txt")[,2])
# select only the variables with "mean" or "std" in their names
X <- X[,grepl("mean|std", names(X))]
# load activity label, and rename the variables
activityLabels = tbl_df(read.table("./UCI HAR Dataset/activity_labels.txt")) %>%
rename(activityIndex = V1, activityName = V2)
# merge y and activity labels, then drop the activity index
names(y) = "activityIndex"
y = merge(y, activityLabels, by = "activityIndex") %>%
select(-activityIndex)
# give tbl subject a descriptive name, then column combine subject, y & X
names(subject) = "subject"
mergedDataset = cbind(subject, y, X)
# group previous dataset by subject & activity name
# then summarize each variables into a second / new dataset
newDataset= group_by(mergedDataset, subject, activityName) %>%
summarize_each(funs(mean))
newDataset
?write.csv
setwd("DataCleaning_Coursera")
write.csv(mergedDataset, file = "mergedDataset.csv")
write.csv(newDataset, file = "newDataset.csv")
groupSummary = group_by(mergedDataset, subject, activityName) %>%
summarize_each(funs(mean))
write.csv(groupSummary, file = "groupSummary.csv")
write.table(groupSummary, sep = ",", row.names = F)
write.table(groupSummary, sep = ",", row.names = F, file = "groupSummary.csv")
write.table(mergedDataset, file = "mergedDataset.csv",sep = ",", row.names = FALSE)
rm(activityLabels, groupSummary)
rm(activityLabels, subject, y, X)
rm(newDataset)
source('~/R/data_cleaning/DataCleaning_Coursera/run_analysis.R')
packages <- c("data.table", "xlsx", "XML")
sapply(packages, require, character.only=TRUE, quietly=TRUE)
url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlInternalTreeParse(url)
rootNode <- xmlRoot(doc)
names(rootNode)
# names(rootNode[[1]])
names(rootNode[[1]][[1]])
zipcode <- xpathSApply(rootNode, "//zipcode", xmlValue)
table(zipcode == 21231)
mergedDataset
mergedDataset = tbl_df(mergedDataset)
mergedDataset
# read and merge train & test datasets
X = rbind(tbl_df(read.table("./UCI HAR Dataset/train/X_train.txt")),
tbl_df(read.table("./UCI HAR Dataset/test/X_test.txt")))
y = rbind(tbl_df(read.table("./UCI HAR Dataset/train/y_train.txt")),
tbl_df(read.table("./UCI HAR Dataset/test/y_test.txt")))
subject = rbind(tbl_df(read.table("./UCI HAR Dataset/train/subject_train.txt")),
tbl_df(read.table("./UCI HAR Dataset/test/subject_test.txt")))
# read features and pass them as variable names of X
names(X) = gsub("\\(|\\)|-", "", read.table("./UCI HAR Dataset/features.txt")[,2])
# select only the variables with "mean" or "std" in their names
X <- X[,grepl("mean|std", names(X))]
# load activity label, and rename the variables
activityLabels = tbl_df(read.table("./UCI HAR Dataset/activity_labels.txt")) %>%
rename(activityIndex = V1, activityName = V2)
# merge y and activity labels, then drop the activity index
names(y) = "activityIndex"
y = merge(y, activityLabels, by = "activityIndex") %>%
select(-activityIndex)
# give tbl subject a descriptive name, then column combine subject, y & X
names(subject) = "subject"
mergedDataset = tbl_df(cbind(subject, y, X))
# group previous dataset by subject & activity name
# then summarize each variables into a second / new dataset
groupSummary = group_by(mergedDataset, subject, activityName) %>%
summarize_each(funs(mean))
# write 2 datasets into csv
write.table(mergedDataset, file = "mergedDataset.csv",sep = ",", row.names = FALSE)
write.table(groupSummary, file = "groupSummary.csv", sep = ",", row.names = FALSE)
rm(doc, packages, rootNode, url, zipcode)
str(mergedDataset)
str(groupSummary)
key(mergedDataset)
head(mergedDataset, n=10)
head(groupSummary, n=10)
q()
